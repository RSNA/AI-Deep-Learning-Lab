{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image Segmentation",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slowvak/AI-Deep-Learning-Lab/blob/master/Image_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ULKtInm7dAMK"
      },
      "source": [
        "# Magicians Corner: Image Segmentation with tf.keras and U-Nets\n",
        "Full Article can be found here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7Plun_k1dAML"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\"><td>\n",
        "<a target=\"_blank\"  href=\"http://colab.research.google.com/github/tensorflow/models/blob/master/samples/outreach/blogs/segmentation_blogpost/image_segmentation.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
        "</td><td>\n",
        "<a target=\"_blank\"  href=\"https://github.com/tensorflow/models/blob/master/samples/outreach/blogs/segmentation_blogpost/image_segmentation.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ODNLPGHKKgr-",
        "colab": {}
      },
      "source": [
        "#Cell #1 --  Set up environment by loading libraries.\n",
        "# Be sure to check that you have GPU runtime\n",
        "import os\n",
        "import glob\n",
        "import zipfile\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "mpl.rcParams['figure.figsize'] = (12,12)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization\n",
        "from keras.layers.core import Dropout, Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Load the {{PROCESSED}} images and the masks for pancreas from RSNA repository\n",
        "# To make load times reasonable, only slices with pancreas are included\n",
        "#  and these are 8 bit JPEG images (compresssed)\n",
        "\n",
        "!rm -rf ./MC4-TensorflowUNet\n",
        "!git clone https://github.com/slowvak/MC4-TensorflowUNet.git\n",
        "\n",
        "!rm -rf images\n",
        "!mkdir images\n",
        "!rm -rf masks\n",
        "!mkdir masks\n",
        "\n",
        "\n",
        "limit = 400  # limit number of subjects due to GPU memory limits\n",
        "\n",
        "\n",
        "for f in os.listdir('./MC4-TensorflowUNet'):\n",
        "    cmd = 'unzip ./MC4-TensorflowUNet/{}'.format(f)\n",
        "    os.system(cmd)\n",
        "    limit = limit - 1\n",
        "    if limit < 0:\n",
        "        break\n",
        "        \n",
        "!mv *-Mask.jpg ./masks\n",
        "!mv *.jpg ./images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wT1kb3q0ghhi",
        "colab": {}
      },
      "source": [
        "#Cell #2 -- We will now split the data into train and test. The syntax is fairly different from FastAI\n",
        "import sys\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "\n",
        "IMG_HEIGHT = IMG_WIDTH =256\n",
        "IMG_CHANNELS = 1\n",
        "img_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "\n",
        "# Get and resize train images and masks\n",
        "image_filenames = os.listdir('./images')\n",
        "mask_filenames = os.listdir('./masks')\n",
        "num_train_examples = int(len(image_filenames) * 0.8) - 1\n",
        "num_val_examples = int(len(image_filenames) - num_train_examples)\n",
        "X_train = np.zeros((num_train_examples, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_train = np.zeros((num_train_examples, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "X_test = np.zeros((num_val_examples, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_test = np.zeros((num_val_examples, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "print('Getting and resizing train images and masks ... ')\n",
        "\n",
        "sys.stdout.flush()\n",
        "\n",
        "\n",
        "n = 0\n",
        "i = 0\n",
        "for f in mask_filenames:\n",
        "    mask = imread('./masks/' + f)\n",
        "#    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    mask = np.expand_dims(mask, axis=2)\n",
        "    img = imread('./images/' + f.replace(\"-Mask.\", \".\"))\n",
        "#    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    img = np.expand_dims(img, axis=2)\n",
        "    if n < num_train_examples:\n",
        "        X_train[n] = img\n",
        "        Y_train[n] = mask\n",
        "    else:\n",
        "        X_test[i] = img\n",
        "        Y_test[i] = mask\n",
        "        i = i+1\n",
        "    n = n + 1\n",
        "\n",
        "print(\"Number of training examples: {}\".format(num_train_examples))\n",
        "print(\"Number of validation examples: {}\".format(num_val_examples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mhvDoZkbcUa1"
      },
      "source": [
        "Display some of the images in our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qUA6SDLhozjj",
        "colab": {}
      },
      "source": [
        "#Cell #3\n",
        "display_num = 5\n",
        "\n",
        "r_choices = np.random.choice(num_train_examples, display_num)\n",
        "\n",
        "plt.figure(figsize=(10, 15))\n",
        "for i in range(0, display_num * 2, 2):\n",
        "  img_num = r_choices[i // 2]\n",
        "  \n",
        "  plt.subplot(display_num, 2, i + 1)\n",
        "  plt.imshow(np.reshape(X_train[img_num], (256,256)), cmap='gray')\n",
        "  plt.title(\"Original Image\")\n",
        "  \n",
        "  plt.subplot(display_num, 2, i + 2)\n",
        "  plt.imshow(np.reshape(Y_train[img_num], (256,256)), cmap='gray')\n",
        "  plt.title(\"Masked Image\")  \n",
        "  \n",
        "plt.suptitle(\"Examples of Images and their Masks\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrv70ZXk6WMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!zip -r images.zip ./images/*\n",
        "!zip -r masks.zip ./masks/*\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmd6NwzVlyjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell 4\n",
        "# Build U-Net model\n",
        "act_fn = 'relu'\n",
        "init_fn = 'he_normal'\n",
        "\n",
        "def dice_coeff(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    # Flatten\n",
        "    y_true_f = tf.reshape(y_true, [-1])\n",
        "    y_pred_f = tf.reshape(y_pred, [-1])\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "#binary cross entropy is another function that can perform well\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "c1 = Conv2D(16, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (s)\n",
        "c1 = Dropout(0.1) (c1)\n",
        "c1 = Conv2D(16, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c1)\n",
        "p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "c2 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (p1)\n",
        "c2 = BatchNormalization()(c2)\n",
        "c2 = Dropout(0.1) (c2)\n",
        "c2 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c2)\n",
        "p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "c3 = Conv2D(64, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (p2)\n",
        "c3 = Dropout(0.2) (c3)\n",
        "c3 = Conv2D(64, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c3)\n",
        "p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "c4 = Conv2D(128, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (p3)\n",
        "c4 = Dropout(0.2) (c4)\n",
        "c4 = Conv2D(128, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c4)\n",
        "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "c5 = Conv2D(256, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (p4)\n",
        "c5 = Dropout(0.3) (c5)\n",
        "c5 = Conv2D(256, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c5)\n",
        "\n",
        "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "u6 = concatenate([u6, c4])\n",
        "c6 = Conv2D(128, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (u6)\n",
        "c6 = Dropout(0.2) (c6)\n",
        "c6 = Conv2D(128, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c6)\n",
        "\n",
        "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "u7 = concatenate([u7, c3])\n",
        "c7 = Conv2D(64, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (u7)\n",
        "c7 = Dropout(0.2) (c7)\n",
        "c7 = Conv2D(64, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c7)\n",
        "\n",
        "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "u8 = concatenate([u8, c2])\n",
        "c8 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (u8)\n",
        "c8 = Dropout(0.1) (c8)\n",
        "c8 = Conv2D(32, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c8)\n",
        "\n",
        "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "u9 = concatenate([u9, c1], axis=3)\n",
        "c9 = Conv2D(16, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (u9)\n",
        "c9 = Dropout(0.1) (c9)\n",
        "c9 = Conv2D(16, (3, 3), activation=act_fn, kernel_initializer=init_fn, padding='same') (c9)\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_loss])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p0tNnmyOdtyr"
      },
      "source": [
        "# Defining custom metrics and loss functions\n",
        "Defining loss and metric functions are simple with Keras. Simply define a function that takes both the True labels for a given example and the Predicted labels for the same given example. \n",
        "Dice loss is a metric that measures overlap. More info on optimizing for Dice coefficient (our dice loss) can be found in the paper, where it was introduced.\n",
        "\n",
        "We use dice loss here because it performs better at class imbalanced problems by design. In addition, maximizing the dice coefficient and IoU metrics are the actual objectives and goals of our segmentation task. Using cross entropy is more of a proxy which is easier to maximize. Instead, we maximize our objective directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gflcWk2Cc8Bi",
        "colab": {}
      },
      "source": [
        "#Cell 5\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "\n",
        "# Fit model\n",
        "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
        "checkpointer = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n",
        "results = model.fit(X_train, Y_train, validation_split=0.2, batch_size=batch_size, epochs=epochs, \n",
        "                    callbacks=[earlystopper, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwtRA1Kq3DbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cell 6\n",
        "# Predict on train, val and test\n",
        "model = load_model('model.h5', custom_objects={'dice_loss': dice_loss})\n",
        "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
        "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
        "preds_test = model.predict(X_test, verbose=1)\n",
        "\n",
        "# Threshold predictions\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
        "\n",
        "# Create list of upsampled test masks\n",
        "preds_test_upsampled = []\n",
        "for i in range(len(preds_test)):\n",
        "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8fTIdJC3FfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cell 7\n",
        "# Perform a sanity check on some random training samples\n",
        "import random\n",
        "\n",
        "ix = random.randint(0, len(preds_train_t))\n",
        "imshow(np.squeeze(X_train[ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_train_t[ix]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}